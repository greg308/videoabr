---
layout: default
title: Real-EVE Real-time Edge-assist Video Enhancement for Joint Denoising and Super-resolution
---

<p> Real-time video applications have received much attention in recent years.  However, the perceived quality of real-time videos in many situations is far from ideal due to  two major obstacles: noise in the video frames caused by limited camera hardware and low resolution caused by bandwidth-limited networks. We propose a new Real-time Edge-assist Video Enhancement (Real-EVE) framework. </p>

<p>Real-EVE includes two key designs: </p>
<li>The video-enhancement deep neural network (VE-DNN), which jointly  eliminates noise and super-resolves videos in real time with a small inference delay;</li>
<li>The video-enhancement-aware adaptive bitrate streaming (VEA-ABR), which adapts sending rate in response to changing network conditions to optimize the video quality posterior to video enhancement.</li>

<h1>System Overview</h1>
We design a system to improve the quality of video transmission in real-time one-way communication scenarios. The system to realize the AI-enhanced real-time video delivery consists of two parts: the sender and the receiver. The sender is a simple device with minimal computational capacities, and the receiver is an edge-computing server with sufficient computational power.  The bandwidth between the sender and the edge server is limited, either because the wireless access link of the sender is not stable, or because the path from the sender to the edge server is through a congested network. The sender sends the low-quality (low-resolution) real-time video to the receiver so that the data rate is not necessarily large. Then, the receiver will enhance the video in real time and the high-quality video is restored. 

<h1>VE-DNN Design</h1>

<p>The design of VE-DNN follows the following three objectives:</p>

<li>First, the output video stream should be of <strong>high quality</strong>. Synchronous design on video denoising and video super-resolution is needed. The direct combination of existing video denoising and video super-resolution approaches in tandem (in either order) is insufficient as the second step will amplify a small error generated from the first step, causing degraded performance in the second step. </li>

<li>Second, the designed DNN should be with a \textbf{small inference delay} to satisfy the need for real-time video. Since a real-time video requires sub-400 ms total delay \cite{itut400}, including network delay, inference delay, and buffer delay, we should limit the inference delay to sub-200 ms to give room to other delays. The direct combination of existing denoising and super-resolution DNN models suffers from redundant computations and results in long processing times.</li>

<li>Third, the DNN should support \textbf{multi-granularity input} and \hspace{0.1pt} \textbf{multi-granularity output}: i.e., input video in \textbf{multi-granularity resolutions} and upsampling in \textbf{multiple scales}. Since the network bandwidth is fluctuating, the raw video could be sent in different resolutions with different bitrates. The DNN should allow the input in different resolutions and output a high-definition video stream with a specified upscale factor to adapt to constraints at the receiver.</li>

<p>The pipeline consists of three sub-modules: the noise-eliminated alignment (NEA) sub-module, the chronological feature propagation (CFP) sub-module, and the multi-scale upsampling (MSU) sub-module. </p>

<h1>VEA-ABR Design</h1>

<p>As for every video chunk, VEA-ABR determines: </p>

<li>in what resolution the chunk should be transmitted;</li>
<li>to what resolution chunk should be super-resolved if it is received at the receiver. </li>

<p>Different transmission delays and processing delays will be incurred for different decisions. Since we consider real-time video instead of stored video, each video chunk has a playout deadline. Each chunk must be able to be played out before the deadline, otherwise, the video chunk will not be played and will be regarded as lost. </p>

<h1>Results</h1>

<h2>System Implementation</h2>

<h2>Effectiveness of VE-DNN Module</h2>

<h2>Effectiveness of VEA-ABR Module</h2>

<h1>Grants</h1>
This project is sponsored by the Toronto Mobility Scheme.

<!-- ul -->

<h1>This is a Heading</h1>
<p>This is a paragraph.</p>
<p>This is another paragraph.</p>

